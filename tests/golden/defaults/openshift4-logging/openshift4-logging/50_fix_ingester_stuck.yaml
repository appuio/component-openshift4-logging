apiVersion: v1
kind: ServiceAccount
metadata:
  annotations: {}
  labels:
    name: loki-ingester-check
  name: loki-ingester-check
  namespace: openshift-logging
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations: {}
  labels:
    name: loki-ingester-check
  name: loki-ingester-check
  namespace: openshift-logging
rules:
  - apiGroups:
      - ''
    resources:
      - pods
      - pods/exec
    verbs:
      - get
      - list
      - watch
      - create
      - delete
      - patch
      - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  annotations: {}
  labels:
    name: loki-ingester-check
  name: loki-ingester-check
  namespace: openshift-logging
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: loki-ingester-check
subjects:
  - kind: ServiceAccount
    name: loki-ingester-check
---
apiVersion: v1
data:
  wal-check.sh: |
    #!/bin/bash

    set -e -o pipefail

    # Check if pod is in stuck state.
    function check_pod() {
      POD_NAME="loki-ingester-${1}"
      echo "checking POD ${POD_NAME}"
      PHASE=$(kubectl -n openshift-logging get po ${POD_NAME} -oyaml | yq '.status.phase')
      if [ ${PHASE} != "Running" ]; then
        return 0
      fi
      READY=$(kubectl -n openshift-logging get po ${POD_NAME} -oyaml | yq '.status.conditions[] | select(.type == "ContainersReady") | .status')
      if [ ${READY} == "True" ]; then
        return 0
      fi
      return 1
    }

    # Check directories of pod and remove non-existing checkpoint if present.
    function check_dir() {
      shopt -s extglob
      POD_NAME="loki-ingester-${1}"
      echo "checking DIR ${POD_NAME}"
      DIR_CHP=$(kubectl -n openshift-logging exec -i ${POD_NAME} -- ls /tmp/wal | grep -o "^checkpoint\.[0-9]*$")
      PATTERN=$(echo ${DIR_CHP} | sed 's/[^0-9]*//g')
      DIR_WAL=$(kubectl -n openshift-logging exec -i ${POD_NAME} -- ls /tmp/wal | grep -o "^0*${PATTERN}$" || exit 0)
      if [ -z $DIR_WAL ]; then
        kubectl -n openshift-logging exec -i ${POD_NAME} -- rm -rf /tmp/wal/${DIR_CHP}
        kubectl -n openshift-logging delete po ${POD_NAME}
      fi
    }

    # Check if pods are in stuck state for longer than ${SLEEP_TIME}.
    # Only fix 1 pod at a time and immediatly exit if it is fixed.
    function fix_pod() {
      if ! check_pod $1; then
        echo "stuck POD, waiting ${SLEEP_TIME}"
        sleep ${SLEEP_TIME}
        if ! check_pod $1; then
          check_dir $1
          exit 0
        fi
      fi
    }

    fix_pod 0
    fix_pod 1

    exit 0
kind: ConfigMap
metadata:
  annotations: {}
  labels:
    name: loki-ingester-check
  name: loki-ingester-check
  namespace: openshift-logging
---
apiVersion: batch/v1
kind: CronJob
metadata:
  annotations: {}
  labels:
    name: loki-ingester-check
  name: loki-ingester-check
  namespace: openshift-logging
spec:
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 0
  jobTemplate:
    spec:
      activeDeadlineSeconds: 360
      backoffLimit: 1
      template:
        spec:
          containers:
            - command:
                - /usr/local/bin/wal-check.sh
              env:
                - name: SLEEP_TIME
                  value: 2m
              image: quay.io/appuio/oc:v4.18
              imagePullPolicy: IfNotPresent
              name: check-pod
              ports: []
              stdin: false
              tty: false
              volumeMounts:
                - mountPath: /usr/local/bin/wal-check.sh
                  name: wal-check
                  readOnly: true
                  subPath: wal-check.sh
          nodeSelector:
            node-role.kubernetes.io/infra: ''
          restartPolicy: Never
          serviceAccountName: loki-ingester-check
          volumes:
            - configMap:
                defaultMode: 364
                name: loki-ingester-check
              name: wal-check
  schedule: '*/10 * * * *'
