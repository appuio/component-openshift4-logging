apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  annotations: {}
  labels:
    name: syn-loki-logging-rules
  name: syn-loki-logging-rules
  namespace: openshift-logging
spec:
  groups:
    - name: logging_loki.alerts
      rules:
        - alert: SYN_LokiRequestErrors
          annotations:
            message: '{{ $labels.job }} {{ $labels.route }} is experiencing {{ printf
              "%.2f" $value }}% errors.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Request-Errors
            summary: At least 10% of requests are responded by 5xx server errors.
          expr: |
            sum(
              job_namespace_route_statuscode:loki_request_duration_seconds_count:irate1m{status_code=~"5.."}
            ) by (job, namespace, route)
            /
            sum(
              job_namespace_route_statuscode:loki_request_duration_seconds_count:irate1m
            ) by (job, namespace, route)
            * 100
            > 10
          for: 15m
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiStackWriteRequestErrors
          annotations:
            message: '{{ printf "%.2f" $value }}% of write requests from {{ $labels.job
              }} in {{ $labels.namespace }} are returned with server errors.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#LokiStack-Write-Request-Errors
            summary: At least 10% of write requests to the lokistack-gateway are responded
              with 5xx server errors.
          expr: |
            sum(
              code_handler_job_namespace:lokistack_gateway_http_requests:irate1m{code=~"5..", handler="push"}
            ) by (job, namespace)
            /
            sum(
              code_handler_job_namespace:lokistack_gateway_http_requests:irate1m{handler="push"}
            ) by (job, namespace)
            * 100
            > 10
          for: 15m
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiStackReadRequestErrors
          annotations:
            message: '{{ printf "%.2f" $value }}% of query requests from {{ $labels.job
              }} in {{ $labels.namespace }} are returned with server errors.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#LokiStack-Read-Request-Errors
            summary: At least 10% of query requests to the lokistack-gateway are responded
              with 5xx server errors.
          expr: |
            sum(
              code_handler_job_namespace:lokistack_gateway_http_requests:irate1m{code=~"5..", handler=~"query|query_range|label|labels|label_values"}
            ) by (job, namespace)
            /
            sum(
              code_handler_job_namespace:lokistack_gateway_http_requests:irate1m{handler=~"query|query_range|label|labels|label_values"}
            ) by (job, namespace)
            * 100
            > 10
          for: 15m
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiRequestPanics
          annotations:
            message: '{{ $labels.job }} is experiencing an increase of {{ $value }}
              panics.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Request-Panics
            summary: A panic was triggered.
          expr: |
            sum(
              increase(
                loki_panic_total[10m]
              )
            ) by (job, namespace)
            > 0
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiRequestLatency
          annotations:
            message: '{{ $labels.job }} {{ $labels.route }} is experiencing {{ printf
              "%.2f" $value }}s 99th percentile latency.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Request-Latency
            summary: The 99th percentile is experiencing high latency (higher than
              1 second).
          expr: |
            histogram_quantile(0.99,
              sum(
                irate(
                  loki_request_duration_seconds_bucket{route!~"(?i).*tail.*"}[1m]
                )
              ) by (job, le, namespace, route)
            )
            > 1
          for: 15m
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiTenantRateLimit
          annotations:
            message: '{{ $labels.job }} {{ $labels.route }} is experiencing 429 errors.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Tenant-Rate-Limit
            summary: At least 10% of requests are responded with the rate limit error
              code.
          expr: |
            sum(
              job_namespace_route_statuscode:loki_request_duration_seconds_count:irate1m{status_code="429"}
            ) by (job, namespace, route)
            /
            sum(
              job_namespace_route_statuscode:loki_request_duration_seconds_count:irate1m
            ) by (job, namespace, route)
            * 100
            > 10
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiStorageSlowWrite
          annotations:
            message: The storage path is experiencing slow write response rates.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Storage-Slow-Write
            summary: The storage path is experiencing slow write response rates.
          expr: |
            histogram_quantile(0.99,
              sum(
                job_le_namespace_operation:loki_boltdb_shipper_request_duration_seconds_bucket:rate5m{operation="WRITE"}
              ) by (job, le, namespace)
            )
            > 1
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiStorageSlowRead
          annotations:
            message: The storage path is experiencing slow read response rates.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Storage-Slow-Read
            summary: The storage path is experiencing slow read response rates.
          expr: |
            histogram_quantile(0.99,
              sum(
                job_le_namespace_operation:loki_boltdb_shipper_request_duration_seconds_bucket:rate5m{operation="Shipper.Query"}
              ) by (job, le, namespace)
            )
            > 5
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiWritePathHighLoad
          annotations:
            message: The write path is experiencing high load.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Write-Path-High-Load
            summary: The write path is experiencing high load, causing backpressure
              storage flushing.
          expr: |
            sum(
              loki_ingester_wal_replay_flushing
            ) by (job, namespace)
            > 0
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiReadPathHighLoad
          annotations:
            message: The read path is experiencing high load.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Read-Path-High-Load
            summary: The read path has high volume of queries, causing longer response
              times.
          expr: |
            histogram_quantile(0.99,
              sum(
                rate(
                  loki_logql_querystats_latency_seconds_bucket[5m]
                )
              ) by (job, le, namespace)
            )
            > 30
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokistackSchemaUpgradesRequired
          annotations:
            message: Object storage schema needs upgrade.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Lokistack-Schema-Upgrades-Required
            summary: The applied storage schema config is old and should be upgraded.
          expr: sum by(stack_id) (lokistack_warnings_count) > 0
          labels:
            resource: '{{ $labels.stack_id}}'
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
