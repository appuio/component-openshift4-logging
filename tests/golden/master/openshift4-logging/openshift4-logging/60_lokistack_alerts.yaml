apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    name: syn-loki-logging-rules
  name: syn-loki-logging-rules
  namespace: openshift-logging
spec:
  groups:
    - name: logging_loki.alerts
      rules:
        - alert: SYN_LokiRequestErrors
          annotations:
            description: '{{ $labels.job }} {{ $labels.route }} is experiencing {{
              printf "%.2f" $value }}% errors.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Request-Errors
            summary: At least 10% of requests are responded by 5xx server errors.
          expr: |
            sum(
              job_namespace_route_statuscode:loki_request_duration_seconds_count:irate1m{status_code=~"5.."}
            ) by (job, namespace, route)
            /
            sum(
              job_namespace_route_statuscode:loki_request_duration_seconds_count:irate1m
            ) by (job, namespace, route)
            * 100
            > 10
          for: 15m
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiStackWriteRequestErrors
          annotations:
            description: '{{ printf "%.2f" $value }}% of write requests from {{ $labels.job
              }} in {{ $labels.namespace }} are returned with server errors.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#LokiStack-Write-Request-Errors
            summary: At least 10% of write requests to the lokistack-gateway are responded
              with 5xx server errors.
          expr: |
            sum(
              code_handler_job_namespace:lokistack_gateway_http_requests:irate1m{code=~"5..", handler="push"}
            ) by (job, namespace)
            /
            sum(
              code_handler_job_namespace:lokistack_gateway_http_requests:irate1m{handler="push"}
            ) by (job, namespace)
            * 100
            > 10
          for: 15m
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiStackReadRequestErrors
          annotations:
            description: '{{ printf "%.2f" $value }}% of query requests from {{ $labels.job
              }} in {{ $labels.namespace }} are returned with server errors.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#LokiStack-Read-Request-Errors
            summary: At least 10% of query requests to the lokistack-gateway are responded
              with 5xx server errors.
          expr: |
            sum(
              code_handler_job_namespace:lokistack_gateway_http_requests:irate1m{code=~"5..", handler=~"query|query_range|label|labels|label_values"}
            ) by (job, namespace)
            /
            sum(
              code_handler_job_namespace:lokistack_gateway_http_requests:irate1m{handler=~"query|query_range|label|labels|label_values"}
            ) by (job, namespace)
            * 100
            > 10
          for: 15m
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiRequestPanics
          annotations:
            description: '{{ $labels.job }} is experiencing an increase of {{ $value
              }} panics.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Request-Panics
            summary: A panic was triggered.
          expr: |
            sum(
              increase(
                loki_panic_total[10m]
              )
            ) by (job, namespace)
            > 0
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiRequestLatency
          annotations:
            description: '{{ $labels.job }} {{ $labels.route }} is experiencing {{
              printf "%.2f" $value }}s 99th percentile latency.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Request-Latency
            summary: The 99th percentile is experiencing high latency (higher than
              1 second).
          expr: |
            histogram_quantile(0.99,
              sum(
                irate(
                  loki_request_duration_seconds_bucket{route!~"(?i).*tail.*"}[1m]
                )
              ) by (job, le, namespace, route)
            )
            > 1
          for: 15m
          labels:
            severity: critical
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiTenantRateLimit
          annotations:
            description: '{{ $labels.job }} {{ $labels.route }} is experiencing 429
              errors.'
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Tenant-Rate-Limit
            summary: At least 10% of requests are responded with the rate limit error
              code.
          expr: |
            sum(
              job_namespace_route_statuscode:loki_request_duration_seconds_count:irate1m{status_code="429"}
            ) by (job, namespace, route)
            /
            sum(
              job_namespace_route_statuscode:loki_request_duration_seconds_count:irate1m
            ) by (job, namespace, route)
            * 100
            > 10
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiStorageSlowWrite
          annotations:
            description: The storage path is experiencing slow write response rates.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Storage-Slow-Write
            summary: The storage path is experiencing slow write response rates.
          expr: |
            histogram_quantile(0.99,
              sum(
                job_le_namespace_operation:loki_boltdb_shipper_request_duration_seconds_bucket:rate5m{operation="WRITE"}
              ) by (job, le, namespace)
            )
            > 1
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiStorageSlowRead
          annotations:
            description: The storage path is experiencing slow read response rates.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Storage-Slow-Read
            summary: The storage path is experiencing slow read response rates.
          expr: |
            histogram_quantile(0.99,
              sum(
                job_le_namespace_operation:loki_boltdb_shipper_request_duration_seconds_bucket:rate5m{operation="Shipper.Query"}
              ) by (job, le, namespace)
            )
            > 5
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiWritePathHighLoad
          annotations:
            description: The write path is experiencing high load.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Write-Path-High-Load
            summary: The write path is experiencing high load, causing backpressure
              storage flushing.
          expr: |
            sum(
              loki_ingester_wal_replay_flushing
            ) by (job, namespace)
            > 0
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiReadPathHighLoad
          annotations:
            description: The read path is experiencing high load.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Loki-Read-Path-High-Load
            summary: The read path has high volume of queries, causing longer response
              times.
          expr: |
            histogram_quantile(0.99,
              sum(
                rate(
                  loki_logql_querystats_latency_seconds_bucket[5m]
                )
              ) by (job, le, namespace)
            )
            > 30
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokiDiscardedSamplesWarning
          annotations:
            description: |-
              Loki in namespace {{ $labels.namespace }} is discarding samples in the "{{ $labels.tenant }}" tenant during ingestion.
              Samples are discarded because of "{{ $labels.reason }}" at a rate of {{ .Value | humanize }} samples per second.
            runbook_url: '[[ .RunbookURL]]#Loki-Discarded-Samples-Warning'
            summary: Loki is discarding samples during ingestion because they fail
              validation.
          expr: |
            sum by(namespace, tenant, reason) (
              irate(loki_discarded_samples_total{
                reason!="rate_limited",
                reason!="per_stream_rate_limit",
                reason!="stream_limit"}[2m])
            )
            > 0
          for: 15m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
        - alert: SYN_LokistackSchemaUpgradesRequired
          annotations:
            description: |-
              The LokiStack "{{ $labels.stack_name }}" in namespace "{{ $labels.stack_namespace }}" is using a storage schema
              configuration that does not contain the latest schema version. It is recommended to update the schema
              configuration to update the schema version to the latest version in the future.
            runbook_url: https://github.com/grafana/loki/blob/main/operator/docs/lokistack/sop.md#Lokistack-Schema-Upgrades-Required
            summary: One or more of the deployed LokiStacks contains an outdated storage
              schema configuration.
          expr: |
            sum (
              lokistack_status_condition{reason="StorageNeedsSchemaUpdate",status="true"}
            ) by (stack_namespace, stack_name)
            > 0
          for: 1m
          labels:
            severity: warning
            syn: 'true'
            syn_component: openshift4-logging
